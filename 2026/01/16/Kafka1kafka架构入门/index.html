<!DOCTYPE html>
<html lang="zh-CN">
<head>
  <meta charset="UTF-8">
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=2">
<meta name="theme-color" content="#222">
<meta name="generator" content="Hexo 5.4.2">
  <link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon-next.png">
  <link rel="icon" type="image/png" sizes="32x32" href="/images/favicon-32x32-next.png">
  <link rel="icon" type="image/png" sizes="16x16" href="/images/favicon-16x16-next.png">
  <link rel="mask-icon" href="/images/logo.svg" color="#222">

<link rel="stylesheet" href="/css/main.css">

<link rel="stylesheet" href="//fonts.googleapis.com/css?family=Lato:300,300italic,400,400italic,700,700italic|JetBrains Mono:300,300italic,400,400italic,700,700italic&display=swap&subset=latin,latin-ext">
<link rel="stylesheet" href="/lib/font-awesome/css/all.min.css">
  <link rel="stylesheet" href="/lib/pace/pace-theme-minimal.min.css">
  <script src="/lib/pace/pace.min.js"></script>

<script id="hexo-configurations">
    var NexT = window.NexT || {};
    var CONFIG = {"hostname":"atffang.github.io","root":"/","scheme":"Mist","version":"7.8.0","exturl":false,"sidebar":{"position":"left","display":"always","padding":18,"offset":12,"onmobile":false},"copycode":{"enable":true,"show_result":true,"style":"flat"},"back2top":{"enable":true,"sidebar":false,"scrollpercent":false},"bookmark":{"enable":false,"color":"#222","save":"auto"},"fancybox":false,"mediumzoom":true,"lazyload":false,"pangu":false,"comments":{"style":"tabs","active":null,"storage":true,"lazyload":false,"nav":null},"algolia":{"hits":{"per_page":10},"labels":{"input_placeholder":"Search for Posts","hits_empty":"We didn't find any results for the search: ${query}","hits_stats":"${hits} results found in ${time} ms"}},"localsearch":{"enable":false,"trigger":"auto","top_n_per_article":1,"unescape":false,"preload":false},"motion":{"enable":true,"async":false,"transition":{"post_block":"fadeIn","post_header":"slideDownIn","post_body":"slideDownIn","coll_header":"slideLeftIn","sidebar":"slideUpIn"}}};
  </script>

  <meta name="description" content="Kafka架构入门：以一个解耦SpringBoot和Python的需求为例。">
<meta property="og:type" content="article">
<meta property="og:title" content="Kafka架构入门">
<meta property="og:url" content="https://atffang.github.io/2026/01/16/Kafka1kafka%E6%9E%B6%E6%9E%84%E5%85%A5%E9%97%A8/index.html">
<meta property="og:site_name" content="Tianyao&#39; s BLOG">
<meta property="og:description" content="Kafka架构入门：以一个解耦SpringBoot和Python的需求为例。">
<meta property="og:locale" content="zh_CN">
<meta property="og:image" content="https://atffang.github.io/2026/01/16/Kafka1kafka%E6%9E%B6%E6%9E%84%E5%85%A5%E9%97%A8/%E6%A0%B8%E5%BF%83%E6%9E%B6%E6%9E%84.jpg">
<meta property="article:published_time" content="2026-01-16T03:33:39.000Z">
<meta property="article:modified_time" content="2026-01-22T04:52:30.360Z">
<meta property="article:author" content="Fang Tianyao">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="https://atffang.github.io/2026/01/16/Kafka1kafka%E6%9E%B6%E6%9E%84%E5%85%A5%E9%97%A8/%E6%A0%B8%E5%BF%83%E6%9E%B6%E6%9E%84.jpg">

<link rel="canonical" href="https://atffang.github.io/2026/01/16/Kafka1kafka%E6%9E%B6%E6%9E%84%E5%85%A5%E9%97%A8/">


<script id="page-configurations">
  // https://hexo.io/docs/variables.html
  CONFIG.page = {
    sidebar: "",
    isHome : false,
    isPost : true,
    lang   : 'zh-CN'
  };
</script>

  <title>Kafka架构入门 | Tianyao' s BLOG</title>
  






  <noscript>
  <style>
  .use-motion .brand,
  .use-motion .menu-item,
  .sidebar-inner,
  .use-motion .post-block,
  .use-motion .pagination,
  .use-motion .comments,
  .use-motion .post-header,
  .use-motion .post-body,
  .use-motion .collection-header { opacity: initial; }

  .use-motion .site-title,
  .use-motion .site-subtitle {
    opacity: initial;
    top: initial;
  }

  .use-motion .logo-line-before i { left: initial; }
  .use-motion .logo-line-after i { right: initial; }
  </style>
</noscript>

<link rel="alternate" href="/atom.xml" title="Tianyao' s BLOG" type="application/atom+xml">
<style>.darkmode--activated{--body-bg-color:#282828;--content-bg-color:#333;--card-bg-color:#555;--text-color:#ccc;--blockquote-color:#bbb;--link-color:#ccc;--link-hover-color:#eee;--brand-color:#ddd;--brand-hover-color:#ddd;--table-row-odd-bg-color:#282828;--table-row-hover-bg-color:#363636;--menu-item-bg-color:#555;--btn-default-bg:#222;--btn-default-color:#ccc;--btn-default-border-color:#555;--btn-default-hover-bg:#666;--btn-default-hover-color:#ccc;--btn-default-hover-border-color:#666;--highlight-background:#282b2e;--highlight-foreground:#a9b7c6;--highlight-gutter-background:#34393d;--highlight-gutter-foreground:#9ca9b6}.darkmode--activated img{opacity:.75}.darkmode--activated img:hover{opacity:.9}.darkmode--activated code{color:#69dbdc;background:0 0}button.darkmode-toggle{z-index:9999}.darkmode-ignore,img{display:flex!important}.beian img{display:inline-block!important}</style></head>

<body itemscope itemtype="http://schema.org/WebPage">
  <div class="container use-motion">
    <div class="headband"></div>

    <header class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-container">
  <div class="site-nav-toggle">
    <div class="toggle" aria-label="切换导航栏">
      <span class="toggle-line toggle-line-first"></span>
      <span class="toggle-line toggle-line-middle"></span>
      <span class="toggle-line toggle-line-last"></span>
    </div>
  </div>

  <div class="site-meta">

    <a href="/" class="brand" rel="start">
      <span class="logo-line-before"><i></i></span>
      <h1 class="site-title">Tianyao' s BLOG</h1>
      <span class="logo-line-after"><i></i></span>
    </a>
      <p class="site-subtitle" itemprop="description">Tianyao</p>
  </div>

  <div class="site-nav-right">
    <div class="toggle popup-trigger">
    </div>
  </div>
</div>




<nav class="site-nav">
  <ul id="menu" class="main-menu menu">
        <li class="menu-item menu-item-home">

    <a href="/" rel="section"><i class="fa fa-home fa-fw"></i>首页</a>

  </li>
        <li class="menu-item menu-item-about">

    <a href="/about/" rel="section"><i class="fa fa-user fa-fw"></i>关于</a>

  </li>
        <li class="menu-item menu-item-tags">

    <a href="/tags/" rel="section"><i class="fa fa-tags fa-fw"></i>标签</a>

  </li>
        <li class="menu-item menu-item-categories">

    <a href="/categories/" rel="section"><i class="fa fa-th fa-fw"></i>分类</a>

  </li>
        <li class="menu-item menu-item-archives">

    <a href="/archives/" rel="section"><i class="fa fa-archive fa-fw"></i>归档</a>

  </li>
  </ul>
</nav>




</div>
    </header>

    
  <div class="back-to-top">
    <i class="fa fa-arrow-up"></i>
    <span>0%</span>
  </div>
  <div class="reading-progress-bar"></div>


    <main class="main">
      <div class="main-inner">
        <div class="content-wrap">
          

          <div class="content post posts-expand">
            

    
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="zh-CN">
    <link itemprop="mainEntityOfPage" href="https://atffang.github.io/2026/01/16/Kafka1kafka%E6%9E%B6%E6%9E%84%E5%85%A5%E9%97%A8/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.png">
      <meta itemprop="name" content="Fang Tianyao">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Tianyao' s BLOG">
    </span>
      <header class="post-header">
        <h1 class="post-title" itemprop="name headline">
          Kafka架构入门
        </h1>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">发表于</span>

              <time title="创建时间：2026-01-16 11:33:39" itemprop="dateCreated datePublished" datetime="2026-01-16T11:33:39+08:00">2026-01-16</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="far fa-calendar-check"></i>
                </span>
                <span class="post-meta-item-text">更新于</span>
                <time title="修改时间：2026-01-22 12:52:30" itemprop="dateModified" datetime="2026-01-22T12:52:30+08:00">2026-01-22</time>
              </span>

          
            <span class="post-meta-item" title="阅读次数" id="busuanzi_container_page_pv" style="display: none;">
              <span class="post-meta-item-icon">
                <i class="fa fa-eye"></i>
              </span>
              <span class="post-meta-item-text">阅读次数：</span>
              <span id="busuanzi_value_page_pv"></span>
            </span><br>
            <span class="post-meta-item" title="本文字数">
              <span class="post-meta-item-icon">
                <i class="far fa-file-word"></i>
              </span>
                <span class="post-meta-item-text">本文字数：</span>
              <span>13k</span>
            </span>
            <span class="post-meta-item" title="阅读时长">
              <span class="post-meta-item-icon">
                <i class="far fa-clock"></i>
              </span>
                <span class="post-meta-item-text">阅读时长 &asymp;</span>
              <span>23 分钟</span>
            </span>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
        <p>Kafka架构入门：以一个解耦SpringBoot和Python的需求为例。</p>
<span id="more"></span>
<h3 id="intro"><a class="markdownIt-Anchor" href="#intro"></a> Intro</h3>
<h4 id="kafka简介"><a class="markdownIt-Anchor" href="#kafka简介"></a> Kafka简介</h4>
<p>由 LinkedIn 开发的 <span style="color: #BB8ED0; font-weight: bold;">Kafka</span> 是一个开源的<strong>分布式事件流平台</strong>（Distributed Event Streaming Platform），旨在解决大规模数据传输中的低延迟与高吞吐难题，后贡献给 Apache 基金会。</p>
<p>在现代微服务架构与大数据体系中，Kafka 早已超越了传统<strong>消息队列</strong>（Message Queue）的范畴，成为处理流式数据、实现系统解耦以及构建实时数据管道的核心基础设施。</p>
<p>从计算机科学的角度定义，Kafka 是一个<strong>基于日志结构（Log-structured）的分布式发布-订阅消息系统</strong>。</p>
<p>其核心设计哲学源于<span style="color: #5aa9e6; font-weight: bold;">预写日志</span>（Write-Ahead Log, WAL）。在数据库设计中，WAL 用于保证事务的原子性和持久性；Kafka 将这一概念泛化，将数据流抽象为一个不可变的、有序的、仅支持追加写入的日志序列。</p>
<div style="background-color: #f7f9fc; border: 1px solid #e1e4e8; border-radius: 15px; padding: 10px; box-shadow: 0 2px 4px rgba(0,0,0,0.05); font-family: -apple-system, BlinkMacSystemFont, 'Segoe UI', Roboto, Helvetica, Arial, sans-serif;"><p style="margin-top: 0; margin-bottom: 6px; color: #333; border-bottom: 2px solid #5aa9e6; padding-bottom: 8px; display: inline-block; font-size: 1.1em; font-weight: 600;">预写日志</p>
<p style="color: #666; font-size: 0.9em; margin: 8px 0; line-height: 1.5;"><span style="color: #333; font-weight: bold;">预写日志（Write-Ahead Log，简称 WAL ）</span>是数据库和分布式系统中保证数据可靠性（Durability）和一致性（Consistency）的核心技术。它的核心逻辑是，在修改真正的数据库文件（数据页）之前，必须先将这次修改的行为记录在日志文件中，并持久化到磁盘上。</p>
</div>
<br>
这种基于预写日志的设计带来了两个本质优势：
- <span style="color: #89986D; font-weight: bold;">持久化（Durability）</span>：消息被直接写入磁盘，而非仅驻留在内存，确保数据不丢失。
- <span style="color: #89986D; font-weight: bold;">顺序 I/O（Sequential I/O）</span>：利用磁盘的顺序读写特性，在机械硬盘（HDD）上也能实现接近内存的随机读写性能。
<h4 id="核心架构组件"><a class="markdownIt-Anchor" href="#核心架构组件"></a> 核心架构组件</h4>
<img src="/2026/01/16/Kafka1kafka%E6%9E%B6%E6%9E%84%E5%85%A5%E9%97%A8/%E6%A0%B8%E5%BF%83%E6%9E%B6%E6%9E%84.jpg" class="" title="sucessful">
<p>Kafka 的运行时架构由以下逻辑实体与物理节点构成：</p>
<h5 id="broker代理节点"><a class="markdownIt-Anchor" href="#broker代理节点"></a> Broker（代理节点）</h5>
<p>Kafka 集群中的物理服务器节点。一个 Kafka 集群由多个 <span style="color: #89986D; font-weight: bold;">Broker</span> 组成。Broker 负责接收生产者的消息、持久化存储数据至磁盘，并响应消费者的拉取请求。</p>
<h5 id="topic主题与-partition分区"><a class="markdownIt-Anchor" href="#topic主题与-partition分区"></a> Topic（主题）与 Partition（分区）</h5>
<ul>
<li>
<p><span style="color: #89986D; font-weight: bold;">Topic</span>：数据的逻辑分类单位。在逻辑上，一个 Topic 可以被视为一个消息流。</p>
</li>
<li>
<p><span style="color: #89986D; font-weight: bold;">Partition</span>：Topic 的物理分片。这是 Kafka 实现<strong>水平扩展（Horizontal Scalability）与并行处理</strong>的关键。</p>
<ul>
<li>一个 Topic 分散在多个 Broker 上的多个 Partition 中。</li>
<li>每个 Partition 是一个有序的日志文件。</li>
<li><strong>Offset（偏移量）</strong>：Partition 中的每条消息都分配有一个唯一的、单调递增的整数 ID，称为 Offset。它唯一标识了消息在分区内的位置。</li>
</ul>
</li>
</ul>
<h5 id="producer生产者"><a class="markdownIt-Anchor" href="#producer生产者"></a> Producer（生产者）</h5>
<p><span style="color: #89986D; font-weight: bold;">Producer</span>负责向 Topic 发送消息的客户端应用。</p>
<ul>
<li><strong>路由策略</strong>：生产者决定将消息发送到 Topic 的哪个 Partition。默认采用<strong>轮询</strong>（Round-robin）策略以实现负载均衡；若消息指定了 Key，则通过哈希算法（<code>Hash(Key) % PartitionCount</code>）确保相同 Key 的消息始终写入同一 Partition，从而保证局部有序性。</li>
</ul>
<h5 id="consumer消费者与-consumer-group消费者组"><a class="markdownIt-Anchor" href="#consumer消费者与-consumer-group消费者组"></a> Consumer（消费者）与 Consumer Group（消费者组）</h5>
<p>这是 Kafka 区别于传统 MQ 最重要的设计模式。</p>
<ul>
<li><span style="color: #89986D; font-weight: bold;">Consumer Group</span>：一个逻辑上的订阅者集合。组内的每个消费者负责消费 Topic 中不同 Partition 的数据。</li>
<li><strong>并行消费机制</strong>：一个 Partition 在同一时刻只能被同一个 Consumer Group 内的一个 Consumer 消费。这保证了消息处理的互斥性与顺序性。</li>
<li><strong>发布/订阅模式</strong>：不同 Consumer Group 之间相互隔离，可以独立消费同一份数据（即广播模式）。</li>
</ul>
<h5 id="replication副本机制与-isr"><a class="markdownIt-Anchor" href="#replication副本机制与-isr"></a> Replication（副本机制）与 ISR</h5>
<p>为了保障高可用性（High Availability），每个 Partition 都有多个副本。</p>
<ul>
<li><strong>Leader Replica</strong>：负责处理所有的读写请求。</li>
<li><strong>Follower Replica</strong>：被动地从 Leader 同步数据，仅用于故障转移（Failover）。</li>
<li><strong>ISR (In-Sync Replicas)</strong>：处于同步状态的副本集合。只有 ISR 中的节点才有资格被选举为新的 Leader。</li>
</ul>
<h4 id="关键技术特性"><a class="markdownIt-Anchor" href="#关键技术特性"></a> 关键技术特性</h4>
<p>Kafka 之所以能达到<strong>每秒百万级的吞吐量</strong>，主要依赖于以下底层机制：</p>
<ul>
<li><span style="color: #89986D; font-weight: bold;">零拷贝（Zero Copy）技术</span> ：在传统的网络传输中，数据需经由“磁盘 -&gt; 内核缓冲区 -&gt; 用户缓冲区 -&gt; Socket 缓冲区 -&gt; 网卡”的多次拷贝。Kafka 利用操作系统的 <code>sendfile</code> 系统调用，直接将数据从 Page Cache 传输到 NIC（网卡）缓冲区，避免了上下文切换与多余的内存拷贝。</li>
<li><span style="color: #89986D; font-weight: bold;">页缓存（Page Cache）利用</span> ：Kafka 并不显式管理内存缓存，而是极度依赖操作系统的 Page Cache。这意味着即使 Java 进程重启，只要操作系统未崩溃，热点数据依然驻留在内存中，极大提升了读取性能。</li>
<li><span style="color: #89986D; font-weight: bold;">批处理（Batching）</span> ：生产者并非逐条发送消息，而是将多条消息打包成 Batch 进行网络传输；服务端同样以 Batch 为单位进行磁盘写入。这有效减少了网络 RTT（往返时延）和磁盘 IOPS。</li>
</ul>
<h4 id="适用场景"><a class="markdownIt-Anchor" href="#适用场景"></a> 适用场景</h4>
<p>基于上述架构，我们列举四个 Kafka 的常用场景：</p>
<div style="background-color: #F0F4F8; border: 1px solid #D9E2EC; border-radius: 15px; padding: 16px; margin-bottom: 20px; box-shadow: 0 4px 6px rgba(0,0,0,0.05); font-family: -apple-system, BlinkMacSystemFont, 'Segoe UI', Roboto, Helvetica, Arial, sans-serif;"> <p style="margin-top: 0; margin-bottom: 8px; color: #243B53; border-bottom: 2px solid #829AB1; padding-bottom: 8px; display: inline-block; font-size: 1.1em; font-weight: 600;"> 1. 异步通信与解耦 (Asynchronous Decoupling)</p> <p style="color: #486581; font-size: 0.95em; margin: 8px 0; line-height: 1.6;"> <span style="font-weight: bold; color: #334E68;">在微服务架构中，缓解上游服务的压力，平滑突发流量（削峰填谷）。</span> </p> <div style="background-color: rgba(255,255,255,0.6); padding: 10px; border-radius: 8px; margin-top: 10px;"> 用户上传了一个 500MB 的 PDF 文档给 Java 后端，Java 不需要死等解析进程解析完，而是直接把任务扔进 Kafka 并立刻告诉用户上传成功。后端的解析进程可以在后台从 Kafka 领取任务解析，互不干扰。 </div> </div><br>
<div style="background-color: #F0F5F1; border: 1px solid #E1E8E3; border-radius: 15px; padding: 16px; margin-bottom: 20px; box-shadow: 0 4px 6px rgba(0,0,0,0.05); font-family: -apple-system, BlinkMacSystemFont, 'Segoe UI', Roboto, Helvetica, Arial, sans-serif;"> <p style="margin-top: 0; margin-bottom: 8px; color: #2D4A3E; border-bottom: 2px solid #8DA399; padding-bottom: 8px; display: inline-block; font-size: 1.1em; font-weight: 600;"> 2. 日志聚合 (Log Aggregation)</p> <p style="color: #4A6359; font-size: 0.95em; margin: 8px 0; line-height: 1.6;"> <span style="font-weight: bold; color: #2F4F42;">作为 ELK (Elasticsearch, Logstash, Kibana) 技术栈的核心缓冲层，收集分布在数千台服务器上的业务日志</span> </p> <div style="background-color: rgba(255,255,255,0.6); padding: 10px; border-radius: 8px; margin-top: 10px;"> 你有 100 台微服务节点，某个订单报错了。如果没有 Kafka，你需要登录 100 台机器去 grep 日志。有了 Kafka后，可以通过Elasticsearch集中管理。 </div> </div><br>
<div style="background-color: #FDF2F2; border: 1px solid #F0E0E0; border-radius: 15px; padding: 16px; margin-bottom: 20px; box-shadow: 0 4px 6px rgba(0,0,0,0.05); font-family: -apple-system, BlinkMacSystemFont, 'Segoe UI', Roboto, Helvetica, Arial, sans-serif;"> <p style="margin-top: 0; margin-bottom: 8px; color: #612F2F; border-bottom: 2px solid #CFA9A9; padding-bottom: 8px; display: inline-block; font-size: 1.1em; font-weight: 600;"> 3. 流式处理 (Stream Processing)</p> <p style="color: #7D4E4E; font-size: 0.95em; margin: 8px 0; line-height: 1.6;"> <span style="font-weight: bold; color: #5C2B2B;">结合 Kafka Streams 或 Apache Flink，对实时数据流进行窗口计算、聚合与变换。</span> </p> <div style="background-color: rgba(255,255,255,0.6); padding: 10px; border-radius: 8px; margin-top: 10px;">用户在短视频APP里每划过一个视频，这个行为就是一个事件流。可以通过 Kafka 实时捕获这些点击，使用流计算引擎立算用户的兴趣点，调整他的推荐算法。 </div> </div><br>
<div style="background-color: #F9F7F3; border: 1px solid #EBE6DC; border-radius: 15px; padding: 16px; margin-bottom: 20px; box-shadow: 0 4px 6px rgba(0,0,0,0.05); font-family: -apple-system, BlinkMacSystemFont, 'Segoe UI', Roboto, Helvetica, Arial, sans-serif;"> <p style="margin-top: 0; margin-bottom: 8px; color: #594D33; border-bottom: 2px solid #B5A886; padding-bottom: 8px; display: inline-block; font-size: 1.1em; font-weight: 600;">4. 事件源 (Event Sourcing)</p> <p style="color: #6E6145; font-size: 0.95em; margin: 8px 0; line-height: 1.6;"> <span style="font-weight: bold; color: #4D422B;">利用 Kafka 的持久化与有序性，将状态的变化记录为一系列事件序列，用于系统状态的重建与审计</span> </p> <div style="background-color: rgba(255,255,255,0.6); padding: 10px; border-radius: 8px; margin-top: 10px;"> 在金融级应用中，仅维护当前的账户余额并不足以满足合规与溯源需求。通过 Kafka 持久化存储存款、消费、转账等一系列事务指令，当发生系统宕机或数据损毁时，系统能够通过顺序重放（Replay）事件序列，在内存中精确重建特定时刻的账户状态。 </div> </div>
<h4 id="基础语法与-cli-操作规范"><a class="markdownIt-Anchor" href="#基础语法与-cli-操作规范"></a> 基础语法与 CLI 操作规范</h4>
<h5 id="创建主题-create-topic"><a class="markdownIt-Anchor" href="#创建主题-create-topic"></a> 创建主题 (Create Topic)</h5>
<p>创建一个名为 <code>tasks</code> 的主题，包含 3 个分区与 1 个副本：</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">bin/kafka-topics.sh --create \</span><br><span class="line">    --topic geo-tasks \</span><br><span class="line">    --bootstrap-server localhost:9092 \</span><br><span class="line">    --partitions 3 \</span><br><span class="line">    --replication-factor 1</span><br></pre></td></tr></table></figure>
<h5 id="查看主题详情-describe-topic"><a class="markdownIt-Anchor" href="#查看主题详情-describe-topic"></a> 查看主题详情 (Describe Topic)</h5>
<p>用于确认分区分布与 Leader 节点位置。</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">bin/kafka-topics.sh --describe \</span><br><span class="line">    --topic geo-tasks \</span><br><span class="line">    --bootstrap-server localhost:9092</span><br></pre></td></tr></table></figure>
<h4 id="生产消息-console-producer"><a class="markdownIt-Anchor" href="#生产消息-console-producer"></a> 生产消息 (Console Producer)</h4>
<p>启动控制台生产者，向主题发送消息。</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">bin/kafka-console-producer.sh \</span><br><span class="line">    --topic geo-tasks \</span><br><span class="line">    --bootstrap-server localhost:9092</span><br><span class="line"><span class="comment"># 输入如下内容后回车</span></span><br><span class="line">&gt; &#123;<span class="string">&quot;id&quot;</span>: 1, <span class="string">&quot;action&quot;</span>: <span class="string">&quot;ingest&quot;</span>, <span class="string">&quot;file&quot;</span>: <span class="string">&quot;map.shp&quot;</span>&#125;</span><br></pre></td></tr></table></figure>
<h5 id="消费消息-console-consumer"><a class="markdownIt-Anchor" href="#消费消息-console-consumer"></a> 消费消息 (Console Consumer)</h5>
<p>启动控制台消费者。<strong>注意</strong>：在生产环境中，必须指定 <code>group.id</code> 以便管理消费进度。</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">bin/kafka-console-consumer.sh \</span><br><span class="line">    --topic geo-tasks \</span><br><span class="line">    --bootstrap-server localhost:9092 \</span><br><span class="line">    --group georag-backend-group \</span><br><span class="line">    --from-beginning</span><br></pre></td></tr></table></figure>
<ul>
<li><code>--from-beginning</code>：表示从 Topic 的起始位置开始消费，而非仅消费启动后新到达的消息。</li>
<li><code>--group</code>：指定消费者组 ID。Kafka 会自动记录该组消费到的 Offset。</li>
</ul>
<h3 id="项目简介"><a class="markdownIt-Anchor" href="#项目简介"></a> 项目简介</h3>
<p>由于本次项目的需求，仅介绍 Kafka 作为 MQ 是的应用方法。</p>
<p>在本项目中，<strong>Spring Boot</strong>持有与前端用户的 WebSocket 连接、HTTP 会话（Session）以及业务数据库的读写权限。而<strong>Python</strong>是后台计算引擎，负责 CPU/GPU 密集型的 AI 运算，但不直接与用户浏览器通信。</p>
<p>在<span style="color: #89986D; font-weight: bold;">任务下发</span>流程中，Spring Boot接受到用户发起的请求后，会做以下工作：</p>
<ul>
<li>生成一个唯一的 <strong>Task ID</strong></li>
<li>将任务载荷（例如 <code>&#123; &quot;taskId&quot;: &quot;1001&quot;, &quot;fileUrl&quot;: &quot;/data/a.shp&quot; &#125;</code>）封装成 JSON。</li>
<li>将消息写入 Kafka 的 <strong>请求主题</strong>（例如 <code>topic-task-request</code>）。</li>
<li>写入 Kafka 后，立即向前端返回 HTTP 200 “Task Received”，释放 Web 线程。</li>
<li>Python 监听 <code>topic-task-request</code>，当轮到该消息时，Python 拉取数据，开始执行运算。</li>
</ul>
<p>在<span style="color: #89986D; font-weight: bold;">结果回传</span>流程中，Python 运算结束，生成结果数据后，会做以下工作：</p>
<ul>
<li>将结果封装成 JSON，<strong>带上之前的 Task ID</strong>（例如 <code>&#123; &quot;taskId&quot;: &quot;1001&quot;, &quot;status&quot;: &quot;DONE&quot;, &quot;vector&quot;: [...] &#125;</code>）。</li>
<li>将消息写入 Kafka 的 <strong>结果主题</strong>（例如 <code>topic-task-result</code>）。这里是写入另一个不同的 Topic，实现了读写分离。</li>
<li>Java（配置了 <code>@KafkaListener</code>）实时监听 <code>topic-task-result</code>。</li>
<li>一旦收到消息，Java 解析 JSON，提取 <code>taskId</code>。</li>
<li>Java 根据 <code>taskId</code> 找到对应的业务记录，找到对应的用户连接，将最终结果实时推送给前端展示。</li>
</ul>
<p>该流程就是一次<span style="color: #5aa9e6; font-weight: bold;">全双工通信</span>。</p>
<div style="background-color: #f7f9fc; border: 1px solid #e1e4e8; border-radius: 15px; padding: 10px; box-shadow: 0 2px 4px rgba(0,0,0,0.05); font-family: -apple-system, BlinkMacSystemFont, 'Segoe UI', Roboto, Helvetica, Arial, sans-serif;"><p style="margin-top: 0; margin-bottom: 6px; color: #333; border-bottom: 2px solid #5aa9e6; padding-bottom: 8px; display: inline-block; font-size: 1.1em; font-weight: 600;">全双工通信</p>
<p style="color: #666; font-size: 0.9em; margin: 8px 0; line-height: 1.5;"><span style="color: #333; font-weight: bold;">全双工通信（Full-Duplex Communication）</span>是数据通信的一种方式，指数据可以同时在两个方向上传输。其要求通信时在通信链路上拥有独立的两条路径，一条用于发送（TX），一条用于接收（RX），并在同一条物理路径上，通过不同的频率（FDD）或极短的时间切片（TDD）来区分发送和接收信号。</p></div>
<br>
<h3 id="spring-boot-集成-kafka"><a class="markdownIt-Anchor" href="#spring-boot-集成-kafka"></a> Spring Boot 集成 Kafka</h3>
<h4 id="基础配置"><a class="markdownIt-Anchor" href="#基础配置"></a> 基础配置</h4>
<p>在微服务架构中，Spring Boot 通过 <code>spring-kafka</code> 项目提供了对 Kafka 客户端的高级抽象。它封装了底层的 <code>KafkaProducer</code> 和 <code>KafkaConsumer</code> API，通过自动配置与模板模式，极大降低了通过 Java 进行流式交互的复杂度。</p>
<p>首先，需要在构建工具中引入 Spring Kafka 的官方 Starter 依赖，如：</p>
<figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">dependency</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">groupId</span>&gt;</span>org.springframework.kafka<span class="tag">&lt;/<span class="name">groupId</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">artifactId</span>&gt;</span>spring-kafka<span class="tag">&lt;/<span class="name">artifactId</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">dependency</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">dependency</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">groupId</span>&gt;</span>com.fasterxml.jackson.core<span class="tag">&lt;/<span class="name">groupId</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">artifactId</span>&gt;</span>jackson-databind<span class="tag">&lt;/<span class="name">artifactId</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">dependency</span>&gt;</span></span><br></pre></td></tr></table></figure>
<p>Kafka 是基于字节流传输的，因此必须明确定义键（Key）与值（Value）的序列化与反序列化策略（SerDes）。考虑到系统后续需与 Python 服务进行交互，采用 JSON 作为 Payload 标准是最好的。</p>
<p>配置文件<code>application.yml</code>如下：</p>
<figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br></pre></td><td class="code"><pre><span class="line">spring:</span><br><span class="line">  kafka:</span><br><span class="line">    bootstrap-servers: localhost:9092 # 集群接入点地址</span><br><span class="line">    </span><br><span class="line">    # 生产者配置</span><br><span class="line">    producer:</span><br><span class="line">      # 重试次数，增强网络抖动下的容错性</span><br><span class="line">      retries: 3 </span><br><span class="line">      # 确认机制：all 代表 Leader 和 ISR 队列所有副本都确认写入才视为成功，保障数据强一致性</span><br><span class="line">      acks: all </span><br><span class="line">      # 批处理大小（字节），提升网络吞吐</span><br><span class="line">      batch-size: 16384 </span><br><span class="line">      # 序列化器：Key 使用字符串，Value 使用 JSON</span><br><span class="line">      key-serializer: org.apache.kafka.common.serialization.StringSerializer</span><br><span class="line">      value-serializer: org.springframework.kafka.support.serializer.JsonSerializer</span><br><span class="line">      properties:</span><br><span class="line">        # 自定义 JSON 类型映射，防止反序列化时的安全限制</span><br><span class="line">        spring.json.trusted.packages: &quot;*&quot;</span><br><span class="line"></span><br><span class="line">    # 消费者配置</span><br><span class="line">    consumer:</span><br><span class="line">      # 默认消费者组 ID，用于标识逻辑订阅者集合</span><br><span class="line">      group-id: georag-backend-group</span><br><span class="line">      # 当 Offset 丢失时的策略：earliest (从头消费), latest (只消费新消息)</span><br><span class="line">      auto-offset-reset: earliest</span><br><span class="line">      # 反序列化器：需与生产者对应</span><br><span class="line">      key-deserializer: org.apache.kafka.common.serialization.StringDeserializer</span><br><span class="line">      value-deserializer: org.springframework.kafka.support.serializer.JsonDeserializer</span><br><span class="line">      properties:</span><br><span class="line">        spring.json.trusted.packages: &quot;*&quot;</span><br></pre></td></tr></table></figure>
<h4 id="生产者"><a class="markdownIt-Anchor" href="#生产者"></a> 生产者</h4>
<p>Spring Boot 提供的 <code>KafkaTemplate</code> 是线程安全的，支持并发发送。在生产环境中，必须采用异步回调来处理发送结果，避免主线程阻塞。</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> org.springframework.kafka.core.KafkaTemplate;</span><br><span class="line"><span class="keyword">import</span> org.springframework.kafka.support.SendResult;</span><br><span class="line"><span class="keyword">import</span> org.springframework.stereotype.Service;</span><br><span class="line"><span class="keyword">import</span> java.util.concurrent.CompletableFuture;</span><br><span class="line"></span><br><span class="line"><span class="meta">@Service</span></span><br><span class="line"><span class="keyword">public</span> <span class="keyword">class</span> <span class="title class_">EventProducer</span> &#123;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">final</span> KafkaTemplate&lt;String, Object&gt; kafkaTemplate;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">public</span> <span class="title function_">EventProducer</span><span class="params">(KafkaTemplate&lt;String, Object&gt; kafkaTemplate)</span> &#123;</span><br><span class="line">        <span class="built_in">this</span>.kafkaTemplate = kafkaTemplate;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="comment">/**</span></span><br><span class="line"><span class="comment">     * 发送数据处理任务</span></span><br><span class="line"><span class="comment">     * <span class="doctag">@param</span> topic 目标主题</span></span><br><span class="line"><span class="comment">     * <span class="doctag">@param</span> key 消息键（通常用于分区路由，如 fileId）</span></span><br><span class="line"><span class="comment">     * <span class="doctag">@param</span> payload 消息载荷实体</span></span><br><span class="line"><span class="comment">     */</span></span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">void</span> <span class="title function_">sendGeoTask</span><span class="params">(String topic, String key, Object payload)</span> &#123;</span><br><span class="line">        <span class="comment">// 执行异步发送</span></span><br><span class="line">        CompletableFuture&lt;SendResult&lt;String, Object&gt;&gt; future = kafkaTemplate.send(topic, key, payload);</span><br><span class="line"></span><br><span class="line">        <span class="comment">// 注册回调函数处理结果</span></span><br><span class="line">        future.whenComplete((result, ex) -&gt; &#123;</span><br><span class="line">            <span class="keyword">if</span> (ex == <span class="literal">null</span>) &#123;</span><br><span class="line">                <span class="comment">// 发送成功：记录元数据（分区信息、偏移量）</span></span><br><span class="line">                System.out.printf(<span class="string">&quot;Sent message to topic: %s, partition: %d, offset: %d%n&quot;</span>,</span><br><span class="line">                        topic,</span><br><span class="line">                        result.getRecordMetadata().partition(),</span><br><span class="line">                        result.getRecordMetadata().offset());</span><br><span class="line">            &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">                <span class="comment">// 发送失败：执行重试逻辑或落库记录死信</span></span><br><span class="line">                System.err.println(<span class="string">&quot;Unable to send message due to: &quot;</span> + ex.getMessage());</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<h4 id="消费者"><a class="markdownIt-Anchor" href="#消费者"></a> 消费者</h4>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> org.apache.kafka.clients.consumer.ConsumerRecord;</span><br><span class="line"><span class="keyword">import</span> org.springframework.kafka.annotation.KafkaListener;</span><br><span class="line"><span class="keyword">import</span> org.springframework.kafka.support.Acknowledgment;</span><br><span class="line"><span class="keyword">import</span> org.springframework.stereotype.Component;</span><br><span class="line"></span><br><span class="line"><span class="meta">@Component</span></span><br><span class="line"><span class="keyword">public</span> <span class="keyword">class</span> <span class="title class_">EventConsumer</span> &#123;</span><br><span class="line"></span><br><span class="line">    <span class="comment">/**</span></span><br><span class="line"><span class="comment">     * 监听处理结果</span></span><br><span class="line"><span class="comment">     * <span class="doctag">@param</span> record 包含元数据和载荷的记录对象</span></span><br><span class="line"><span class="comment">     * <span class="doctag">@param</span> ack 手动提交确认对象（如开启手动提交模式）</span></span><br><span class="line"><span class="comment">     */</span></span><br><span class="line">    <span class="meta">@KafkaListener(topics = &quot;topic-knowledge-result&quot;, groupId = &quot;georag-backend-group&quot;)</span></span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">void</span> <span class="title function_">handleGeoResult</span><span class="params">(ConsumerRecord&lt;String, String&gt; record, Acknowledgment ack)</span> &#123;</span><br><span class="line">        <span class="keyword">try</span> &#123;</span><br><span class="line">            <span class="type">String</span> <span class="variable">fileId</span> <span class="operator">=</span> record.key();</span><br><span class="line">            <span class="type">String</span> <span class="variable">resultJson</span> <span class="operator">=</span> record.value();</span><br><span class="line"></span><br><span class="line">            <span class="comment">// 业务逻辑：处理 Python 返回的结果</span></span><br><span class="line">            System.out.printf(<span class="string">&quot;Received result for file %s from partition %d%n&quot;</span>, fileId, record.partition());</span><br><span class="line">            </span><br><span class="line">            <span class="comment">// 此处调用 WebSocket 服务通知前端或更新数据库状态</span></span><br><span class="line">            processResult(fileId, resultJson);</span><br><span class="line"></span><br><span class="line">            <span class="comment">// 显式提交 Offset（如果配置了手动提交）</span></span><br><span class="line">            ack.acknowledge();</span><br><span class="line">        &#125; <span class="keyword">catch</span> (Exception e) &#123;</span><br><span class="line">            <span class="comment">// 异常处理：记录日志，且不提交 Offset 以触发重试</span></span><br><span class="line">            System.err.println(<span class="string">&quot;Error consuming message: &quot;</span> + e.getMessage());</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">void</span> <span class="title function_">processResult</span><span class="params">(String fileId, String data)</span> &#123;</span><br><span class="line">        <span class="comment">// 具体业务逻辑实现</span></span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<h3 id="python-集成-kafka"><a class="markdownIt-Anchor" href="#python-集成-kafka"></a> Python 集成 Kafka</h3>
<p>在 Python 生态中，主流的 Kafka 客户端库有两个：</p>
<ol>
<li><strong><code>kafka-python</code></strong>：纯 Python 实现，安装简便，社区活跃，适合大多数中等吞吐场景</li>
<li><strong><code>confluent-kafka</code></strong>：基于 C 语言 <code>librdkafka</code> 的封装，性能极高，适合超高吞吐场景。</li>
</ol>
<p>考虑到个人的项目属于计算密集型而非 I/O 密集型（瓶颈在于 GPU 推理而非网络吞吐），采用代码可读性更强的 <code>kafka-python</code> 是合理的工程选择。</p>
<p>安装依赖：</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">pip install kafka-python</span><br></pre></td></tr></table></figure>
<h4 id="消费者-2"><a class="markdownIt-Anchor" href="#消费者-2"></a> 消费者</h4>
<p>为了接收 Java 端 <code>JsonSerializer</code> 发送的消息，Python 端必须严格遵循对应的反序列化协议。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> json</span><br><span class="line"><span class="keyword">import</span> logging</span><br><span class="line"><span class="keyword">import</span> time</span><br><span class="line"><span class="keyword">import</span> signal</span><br><span class="line"><span class="keyword">import</span> sys</span><br><span class="line"><span class="keyword">from</span> kafka <span class="keyword">import</span> KafkaConsumer, KafkaProducer</span><br><span class="line"><span class="keyword">from</span> kafka.errors <span class="keyword">import</span> KafkaError</span><br><span class="line"></span><br><span class="line">KAFKA_BOOTSTRAP_SERVERS = [<span class="string">&#x27;localhost:9092&#x27;</span>]</span><br><span class="line">TOPIC_INPUT = <span class="string">&#x27;topic-knowledge-ingest&#x27;</span>   <span class="comment"># 接收任务的主题</span></span><br><span class="line">TOPIC_OUTPUT = <span class="string">&#x27;topic-knowledge-result&#x27;</span>  <span class="comment"># 回传结果的主题</span></span><br><span class="line">GROUP_ID = <span class="string">&#x27;georag-python-worker-group&#x27;</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 日志配置</span></span><br><span class="line">logging.basicConfig(</span><br><span class="line">    level=logging.INFO,</span><br><span class="line">    <span class="built_in">format</span>=<span class="string">&#x27;%(asctime)s - %(name)s - %(levelname)s - %(message)s&#x27;</span></span><br><span class="line">)</span><br><span class="line">logger = logging.getLogger(__name__)</span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">GeoRAGWorker</span>:</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self</span>):</span><br><span class="line">        self.running = <span class="literal">True</span></span><br><span class="line">        </span><br><span class="line">        <span class="comment"># 初始化消费者</span></span><br><span class="line">        <span class="comment"># 关键配置：enable_auto_commit=False 确保业务处理完才提交偏移量</span></span><br><span class="line">        self.consumer = KafkaConsumer(</span><br><span class="line">            TOPIC_INPUT,</span><br><span class="line">            bootstrap_servers=KAFKA_BOOTSTRAP_SERVERS,</span><br><span class="line">            group_id=GROUP_ID,</span><br><span class="line">            auto_offset_reset=<span class="string">&#x27;earliest&#x27;</span>,</span><br><span class="line">            enable_auto_commit=<span class="literal">False</span>,</span><br><span class="line">            value_deserializer=<span class="keyword">lambda</span> m: json.loads(m.decode(<span class="string">&#x27;utf-8&#x27;</span>)),</span><br><span class="line">            <span class="comment"># 防止长任务导致的 Rebalance (根据实际业务耗时调整)</span></span><br><span class="line">            max_poll_interval_ms=<span class="number">600000</span> </span><br><span class="line">        )</span><br><span class="line"></span><br><span class="line">        <span class="comment"># 初始化生产者</span></span><br><span class="line">        self.producer = KafkaProducer(</span><br><span class="line">            bootstrap_servers=KAFKA_BOOTSTRAP_SERVERS,</span><br><span class="line">            value_serializer=<span class="keyword">lambda</span> v: json.dumps(v).encode(<span class="string">&#x27;utf-8&#x27;</span>)</span><br><span class="line">        )</span><br><span class="line">        </span><br><span class="line">        <span class="comment"># 注册信号处理，用于优雅退出</span></span><br><span class="line">        signal.signal(signal.SIGINT, self.shutdown)</span><br><span class="line">        signal.signal(signal.SIGTERM, self.shutdown)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">shutdown</span>(<span class="params">self, signum, frame</span>):</span><br><span class="line">        logger.info(<span class="string">&quot;Received shutdown signal. Stopping worker...&quot;</span>)</span><br><span class="line">        self.running = <span class="literal">False</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">start</span>(<span class="params">self</span>):</span><br><span class="line">        logger.info(<span class="string">f&quot;Worker started. Listening on <span class="subst">&#123;TOPIC_INPUT&#125;</span>...&quot;</span>)</span><br><span class="line">        </span><br><span class="line">        <span class="keyword">try</span>:</span><br><span class="line">            <span class="comment"># 循环拉取消息，timeout_ms 允许在没有消息时让出 CPU 检查 running 状态</span></span><br><span class="line">            <span class="keyword">while</span> self.running:</span><br><span class="line">                <span class="comment"># poll 返回的是一个字典 &#123;TopicPartition: [Record, ...]&#125;</span></span><br><span class="line">                msg_pack = self.consumer.poll(timeout_ms=<span class="number">1000</span>) </span><br><span class="line">                </span><br><span class="line">                <span class="keyword">for</span> partition, messages <span class="keyword">in</span> msg_pack.items():</span><br><span class="line">                    <span class="keyword">for</span> message <span class="keyword">in</span> messages:</span><br><span class="line">                        <span class="keyword">if</span> <span class="keyword">not</span> self.running: <span class="keyword">break</span></span><br><span class="line">                        self._handle_single_message(message)</span><br><span class="line">        <span class="keyword">except</span> Exception <span class="keyword">as</span> e:</span><br><span class="line">            logger.error(<span class="string">f&quot;Critical worker error: <span class="subst">&#123;e&#125;</span>&quot;</span>, exc_info=<span class="literal">True</span>)</span><br><span class="line">        <span class="keyword">finally</span>:</span><br><span class="line">            self.consumer.close()</span><br><span class="line">            self.producer.close()</span><br><span class="line">            logger.info(<span class="string">&quot;Kafka connections closed. Bye.&quot;</span>)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">_handle_single_message</span>(<span class="params">self, message</span>):</span><br><span class="line">        <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">        处理单条消息的生命周期：解析 -&gt; 执行 -&gt; 回传 -&gt; 提交</span></span><br><span class="line"><span class="string">        &quot;&quot;&quot;</span></span><br><span class="line">        <span class="keyword">try</span>:</span><br><span class="line">            payload = message.value</span><br><span class="line">            task_id = payload.get(<span class="string">&#x27;fileId&#x27;</span>) <span class="keyword">or</span> payload.get(<span class="string">&#x27;taskId&#x27;</span>)</span><br><span class="line">            </span><br><span class="line">            logger.info(<span class="string">f&quot;Received Task [<span class="subst">&#123;task_id&#125;</span>] from partition <span class="subst">&#123;message.partition&#125;</span>&quot;</span>)</span><br><span class="line"></span><br><span class="line">            <span class="comment"># 1. 【核心】执行业务逻辑 (占位)</span></span><br><span class="line">            result_data = self.process_business_logic(payload)</span><br><span class="line"></span><br><span class="line">            <span class="comment"># 2. 回传结果</span></span><br><span class="line">            self._send_result(task_id, result_data)</span><br><span class="line"></span><br><span class="line">            <span class="comment"># 3. 手动提交偏移量 (Ack)</span></span><br><span class="line">            <span class="comment"># 注意：此处使用的是同步提交 commit_sync 或 异步 commit_async</span></span><br><span class="line">            <span class="comment"># 为了数据绝对安全，关键任务建议使用 commit_sync</span></span><br><span class="line">            self.consumer.commit() </span><br><span class="line">            </span><br><span class="line">        <span class="keyword">except</span> Exception <span class="keyword">as</span> e:</span><br><span class="line">            logger.error(<span class="string">f&quot;Error processing message: <span class="subst">&#123;e&#125;</span>&quot;</span>)</span><br><span class="line">            <span class="comment"># <span class="doctag">TODO:</span> 可以在此处增加死信队列 (DLQ) 的投递逻辑</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">process_business_logic</span>(<span class="params">self, payload</span>):</span><br><span class="line">        <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">        [占位函数] 在此处填入你的 GeoRAG / 深度学习推理逻辑</span></span><br><span class="line"><span class="string">        &quot;&quot;&quot;</span></span><br><span class="line">        <span class="comment"># --- 业务代码开始 ---</span></span><br><span class="line">        </span><br><span class="line">        <span class="comment"># --- 业务代码结束 ---</span></span><br><span class="line">        </span><br><span class="line">        <span class="keyword">return</span> &#123;</span><br><span class="line">            <span class="string">&quot;status&quot;</span>: <span class="string">&quot;SUCCESS&quot;</span>, </span><br><span class="line">            <span class="string">&quot;message&quot;</span>: <span class="string">&quot;Vectorization complete&quot;</span>, </span><br><span class="line">            <span class="string">&quot;vector_ids&quot;</span>: [<span class="number">101</span>, <span class="number">102</span>, <span class="number">103</span>] <span class="comment"># 模拟结果</span></span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">_send_result</span>(<span class="params">self, task_id, data</span>):</span><br><span class="line">        <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">        发送处理结果到输出 Topic</span></span><br><span class="line"><span class="string">        &quot;&quot;&quot;</span></span><br><span class="line">        response = &#123;</span><br><span class="line">            <span class="string">&quot;taskId&quot;</span>: task_id,</span><br><span class="line">            <span class="string">&quot;timestamp&quot;</span>: time.time(),</span><br><span class="line">            <span class="string">&quot;payload&quot;</span>: data</span><br><span class="line">        &#125;</span><br><span class="line">        future = self.producer.send(TOPIC_OUTPUT, value=response)</span><br><span class="line">        <span class="comment"># 简单的阻塞等待确认，保证结果一定写入 Kafka</span></span><br><span class="line">        future.get(timeout=<span class="number">10</span>)</span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">&#x27;__main__&#x27;</span>:</span><br><span class="line">    GeoRAGWorker().start()</span><br></pre></td></tr></table></figure>
<h3 id="死信队列"><a class="markdownIt-Anchor" href="#死信队列"></a> 死信队列</h3>
<p>若缺乏隔离机制，一条无法被正常处理的消息（即“毒丸消息”，Poison Pill）会导致消费者陷入 <strong>“读取 -&gt; 崩溃 -&gt; 重启 -&gt; 再读取”</strong> 的死循环，进而阻塞分区内后续所有正常消息的处理。<span style="color: #BB8ED0; font-weight: bold;">死信队列（Dead Letter Queue, DLQ）</span> 正是解决这一问题的标准架构模式。</p>
<p>在没有 DLQ 的架构中，消费者的默认行为通常是“失败重试”。然而，对于确定性错误（如数据格式损坏、业务逻辑冲突），无限重试毫无意义，只会导致消费滞后迅速累积，最终拖垮整个处理链路。</p>
<p>引入 DLQ 后，系统的容错逻辑变更为：</p>
<ol>
<li><span style="color: #89986D; font-weight: bold;">重试（Retry）</span>：在遇到瞬态错误（如网络抖动）时，进行有限次数的重试。</li>
<li><span style="color: #89986D; font-weight: bold;">隔离（Isolate）</span>：当重试耗尽或遇到非恢复性错误时，将该消息转移至 DLQ 主题。</li>
<li><span style="color: #89986D; font-weight: bold;">提交（Commit）</span>：向 Kafka 提交原消息的 Offset，欺骗 Broker 认为该消息已被消费，从而让消费者指针向前移动，继续处理后续的正常数据。</li>
</ol>
<p>以下是死信生产的标准时序流程：</p>
<ol>
<li><strong>消息拉取 (Fetch)</strong>：消费者从 <code>topic-knowledge-ingest</code> 获取 Offset 为 <code>N</code> 的消息。</li>
<li><strong>业务试错 (Try)</strong>：将 Payload 传入核心业务逻辑。</li>
<li><strong>异常抛出 (Throw)</strong>：业务逻辑因数据格式错误抛出 <code>ValueError</code> 或 <code>JSONDecodeError</code>。</li>
<li><strong>异常捕获 (Catch)</strong>：在最外层拦截该异常，阻止 Worker 崩溃。</li>
<li><strong>死信封装 (Wrap)</strong>：将原始消息 + 错误堆栈打包成新的 JSON 对象。</li>
<li><strong>死信投递 (Produce)</strong>：将封装包发送至 <code>topic-knowledge-ingest-dlq</code>。</li>
<li><strong>伪装成功 (Commit)</strong>：向 Kafka 提交 Offset <code>N</code>，欺骗 Broker 认为该消息已被“成功消费”。从而让消费者指针移动到 <code>N+1</code>，继续处理后续正常任务。</li>
</ol>

    </div>

    
    
    

      <footer class="post-footer">

        


        
    <div class="post-nav">
      <div class="post-nav-item">
    <a href="/2026/01/15/Redis1-3%E7%A7%8D%E5%B8%B8%E7%94%A8%E7%9A%84%E7%BC%93%E5%AD%98%E8%AF%BB%E5%86%99%E7%AD%96%E7%95%A5/" rel="prev" title="Redis：三种常用的缓存读写策略">
      <i class="fa fa-chevron-left"></i> Redis：三种常用的缓存读写策略
    </a></div>
      <div class="post-nav-item">
    <a href="/2026/01/26/RedisTokenBucket/" rel="next" title="Redis：Token Bucket 令牌桶算法">
      Redis：Token Bucket 令牌桶算法 <i class="fa fa-chevron-right"></i>
    </a></div>
    </div>
      </footer>
    
  </article>
  
  
  



          </div>
          

<script>
  window.addEventListener('tabs:register', () => {
    let { activeClass } = CONFIG.comments;
    if (CONFIG.comments.storage) {
      activeClass = localStorage.getItem('comments_active') || activeClass;
    }
    if (activeClass) {
      let activeTab = document.querySelector(`a[href="#comment-${activeClass}"]`);
      if (activeTab) {
        activeTab.click();
      }
    }
  });
  if (CONFIG.comments.storage) {
    window.addEventListener('tabs:click', event => {
      if (!event.target.matches('.tabs-comment .tab-content .tab-pane')) return;
      let commentClass = event.target.classList[1];
      localStorage.setItem('comments_active', commentClass);
    });
  }
</script>

        </div>
          
  
  <div class="toggle sidebar-toggle">
    <span class="toggle-line toggle-line-first"></span>
    <span class="toggle-line toggle-line-middle"></span>
    <span class="toggle-line toggle-line-last"></span>
  </div>

  <aside class="sidebar">
    <div class="sidebar-inner">

      <ul class="sidebar-nav motion-element">
        <li class="sidebar-nav-toc">
          文章目录
        </li>
        <li class="sidebar-nav-overview">
          站点概览
        </li>
      </ul>

      <!--noindex-->
      <div class="post-toc-wrap sidebar-panel">
          <div class="post-toc motion-element"><ol class="nav"><li class="nav-item nav-level-3"><a class="nav-link" href="#intro"><span class="nav-number">1.</span> <span class="nav-text"> Intro</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#kafka%E7%AE%80%E4%BB%8B"><span class="nav-number">1.1.</span> <span class="nav-text"> Kafka简介</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#%E6%A0%B8%E5%BF%83%E6%9E%B6%E6%9E%84%E7%BB%84%E4%BB%B6"><span class="nav-number">1.2.</span> <span class="nav-text"> 核心架构组件</span></a><ol class="nav-child"><li class="nav-item nav-level-5"><a class="nav-link" href="#broker%E4%BB%A3%E7%90%86%E8%8A%82%E7%82%B9"><span class="nav-number">1.2.1.</span> <span class="nav-text"> Broker（代理节点）</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#topic%E4%B8%BB%E9%A2%98%E4%B8%8E-partition%E5%88%86%E5%8C%BA"><span class="nav-number">1.2.2.</span> <span class="nav-text"> Topic（主题）与 Partition（分区）</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#producer%E7%94%9F%E4%BA%A7%E8%80%85"><span class="nav-number">1.2.3.</span> <span class="nav-text"> Producer（生产者）</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#consumer%E6%B6%88%E8%B4%B9%E8%80%85%E4%B8%8E-consumer-group%E6%B6%88%E8%B4%B9%E8%80%85%E7%BB%84"><span class="nav-number">1.2.4.</span> <span class="nav-text"> Consumer（消费者）与 Consumer Group（消费者组）</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#replication%E5%89%AF%E6%9C%AC%E6%9C%BA%E5%88%B6%E4%B8%8E-isr"><span class="nav-number">1.2.5.</span> <span class="nav-text"> Replication（副本机制）与 ISR</span></a></li></ol></li><li class="nav-item nav-level-4"><a class="nav-link" href="#%E5%85%B3%E9%94%AE%E6%8A%80%E6%9C%AF%E7%89%B9%E6%80%A7"><span class="nav-number">1.3.</span> <span class="nav-text"> 关键技术特性</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#%E9%80%82%E7%94%A8%E5%9C%BA%E6%99%AF"><span class="nav-number">1.4.</span> <span class="nav-text"> 适用场景</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#%E5%9F%BA%E7%A1%80%E8%AF%AD%E6%B3%95%E4%B8%8E-cli-%E6%93%8D%E4%BD%9C%E8%A7%84%E8%8C%83"><span class="nav-number">1.5.</span> <span class="nav-text"> 基础语法与 CLI 操作规范</span></a><ol class="nav-child"><li class="nav-item nav-level-5"><a class="nav-link" href="#%E5%88%9B%E5%BB%BA%E4%B8%BB%E9%A2%98-create-topic"><span class="nav-number">1.5.1.</span> <span class="nav-text"> 创建主题 (Create Topic)</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#%E6%9F%A5%E7%9C%8B%E4%B8%BB%E9%A2%98%E8%AF%A6%E6%83%85-describe-topic"><span class="nav-number">1.5.2.</span> <span class="nav-text"> 查看主题详情 (Describe Topic)</span></a></li></ol></li><li class="nav-item nav-level-4"><a class="nav-link" href="#%E7%94%9F%E4%BA%A7%E6%B6%88%E6%81%AF-console-producer"><span class="nav-number">1.6.</span> <span class="nav-text"> 生产消息 (Console Producer)</span></a><ol class="nav-child"><li class="nav-item nav-level-5"><a class="nav-link" href="#%E6%B6%88%E8%B4%B9%E6%B6%88%E6%81%AF-console-consumer"><span class="nav-number">1.6.1.</span> <span class="nav-text"> 消费消息 (Console Consumer)</span></a></li></ol></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E9%A1%B9%E7%9B%AE%E7%AE%80%E4%BB%8B"><span class="nav-number">2.</span> <span class="nav-text"> 项目简介</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#spring-boot-%E9%9B%86%E6%88%90-kafka"><span class="nav-number">3.</span> <span class="nav-text"> Spring Boot 集成 Kafka</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#%E5%9F%BA%E7%A1%80%E9%85%8D%E7%BD%AE"><span class="nav-number">3.1.</span> <span class="nav-text"> 基础配置</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#%E7%94%9F%E4%BA%A7%E8%80%85"><span class="nav-number">3.2.</span> <span class="nav-text"> 生产者</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#%E6%B6%88%E8%B4%B9%E8%80%85"><span class="nav-number">3.3.</span> <span class="nav-text"> 消费者</span></a></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#python-%E9%9B%86%E6%88%90-kafka"><span class="nav-number">4.</span> <span class="nav-text"> Python 集成 Kafka</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#%E6%B6%88%E8%B4%B9%E8%80%85-2"><span class="nav-number">4.1.</span> <span class="nav-text"> 消费者</span></a></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E6%AD%BB%E4%BF%A1%E9%98%9F%E5%88%97"><span class="nav-number">5.</span> <span class="nav-text"> 死信队列</span></a></li></ol></div>
      </div>
      <!--/noindex-->

      <div class="site-overview-wrap sidebar-panel">
        <div class="site-author motion-element" itemprop="author" itemscope itemtype="http://schema.org/Person">
    <img class="site-author-image" itemprop="image" alt="Fang Tianyao"
      src="/images/avatar.png">
  <p class="site-author-name" itemprop="name">Fang Tianyao</p>
  <div class="site-description" itemprop="description"></div>
</div>
<div class="site-state-wrap motion-element">
  <nav class="site-state">
      <div class="site-state-item site-state-posts">
          <a href="/archives/">
        
          <span class="site-state-item-count">60</span>
          <span class="site-state-item-name">日志</span>
        </a>
      </div>
      <div class="site-state-item site-state-categories">
            <a href="/categories/">
          
        <span class="site-state-item-count">9</span>
        <span class="site-state-item-name">分类</span></a>
      </div>
  </nav>
</div>
  <div class="links-of-author motion-element">
      <span class="links-of-author-item">
        <a href="mailto:fty643737159@gmail.com" title="欢迎交流 E-Mail → mailto:fty643737159@gmail.com" rel="noopener" target="_blank"><i class="fa fa-envelope fa-fw"></i>欢迎交流 E-Mail</a>
      </span>
      <span class="links-of-author-item">
        <a href="https://geo.ecnu.edu.cn/" title="华东师范大学，地图学与地理信息系统 → https:&#x2F;&#x2F;geo.ecnu.edu.cn&#x2F;" rel="noopener" target="_blank"><i class="fab fa-google fa-fw"></i>华东师范大学，地图学与地理信息系统</a>
      </span>
  </div>



      </div>

    </div>
  </aside>
  <div id="sidebar-dimmer"></div>


      </div>
    </main>

    <footer class="footer">
      <div class="footer-inner">
        

        

<div class="copyright">
  
  &copy; 
  <span itemprop="copyrightYear">2026</span>
  <span class="with-love">
    <i class="fa fa-terminal"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">Fang Tianyao</span>
    <span class="post-meta-divider">|</span>
    <span class="post-meta-item-icon">
      <i class="fa fa-chart-area"></i>
    </span>
      <span class="post-meta-item-text">站点总字数：</span>
    <span title="站点总字数">316k</span>
    <span class="post-meta-divider">|</span>
    <span class="post-meta-item-icon">
      <i class="fa fa-coffee"></i>
    </span>
      <span class="post-meta-item-text">站点阅读时长 &asymp;</span>
    <span title="站点阅读时长">9:34</span>
</div>

        
<div class="busuanzi-count">
  <script async src="https://busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script>
    <span class="post-meta-item" id="busuanzi_container_site_uv" style="display: none;">
      <span class="post-meta-item-icon">
        <i class="fa fa-user"></i>
      </span>
      <span class="site-uv" title="总访客量">
        <span id="busuanzi_value_site_uv"></span>
      </span>
    </span>
    <span class="post-meta-divider">|</span>
    <span class="post-meta-item" id="busuanzi_container_site_pv" style="display: none;">
      <span class="post-meta-item-icon">
        <i class="fa fa-eye"></i>
      </span>
      <span class="site-pv" title="总访问量">
        <span id="busuanzi_value_site_pv"></span>
      </span>
    </span>
</div>








      </div>
    </footer>
  </div>

  
  <script src="/lib/anime.min.js"></script>
  <script src="//cdn.jsdelivr.net/npm/medium-zoom@1/dist/medium-zoom.min.js"></script>
  <script src="/lib/velocity/velocity.min.js"></script>
  <script src="/lib/velocity/velocity.ui.min.js"></script>

<script src="/js/utils.js"></script>

<script src="/js/motion.js"></script>


<script src="/js/schemes/muse.js"></script>


<script src="/js/next-boot.js"></script>




  











<script>
document.querySelectorAll('.pdfobject-container').forEach(element => {
  let url = element.dataset.target;
  let pdfOpenParams = {
    navpanes : 0,
    toolbar  : 0,
    statusbar: 0,
    pagemode : 'thumbs',
    view     : 'FitH'
  };
  let pdfOpenFragment = '#' + Object.entries(pdfOpenParams).map(([key, value]) => `${key}=${encodeURIComponent(value)}`).join('&');
  let fullURL = `/lib/pdf/web/viewer.html?file=${encodeURIComponent(url)}${pdfOpenFragment}`;

  if (NexT.utils.supportsPDFs()) {
    element.innerHTML = `<embed class="pdfobject" src="${url + pdfOpenFragment}" type="application/pdf" style="height: ${element.dataset.height};">`;
  } else {
    element.innerHTML = `<iframe src="${fullURL}" style="height: ${element.dataset.height};" frameborder="0"></iframe>`;
  }
});
</script>




  

  
      
<link rel="stylesheet" href="//cdn.jsdelivr.net/npm/katex@0/dist/katex.min.css">


  

</body>
</html>
